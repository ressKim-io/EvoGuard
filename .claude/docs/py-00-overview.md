# Python ML Stack Best Practices Guide

> ğŸ“… Last Updated: January 2026

## ğŸ“¦ Stack Overview

| Package | Version | Purpose |
|---------|---------|---------|
| Python | 3.12.8 | Runtime |
| PyTorch | 2.5.1+cu124 | Deep Learning Framework |
| transformers | 4.48.3 | Pre-trained Models |
| PEFT | 0.14.0 | Parameter-Efficient Fine-Tuning |
| bitsandbytes | 0.49.1 | Quantization |
| accelerate | 1.5.2 | Distributed Training |
| datasets | 3.2.0 | Data Loading |
| MLflow | 2.22.4 | Experiment Tracking |

## ğŸ“ Guide Structure

```
python-ml-guide/
â”œâ”€â”€ README.md                    # ì´ íŒŒì¼
â”œâ”€â”€ 01_project_setup.md          # uv + pyproject.toml ì„¤ì •
â”œâ”€â”€ 02_pytorch_best_practices.md # PyTorch ìµœì í™”
â”œâ”€â”€ 03_transformers_peft.md      # Transformers & PEFT
â”œâ”€â”€ 04_quantization.md           # bitsandbytes ì–‘ìí™”
â”œâ”€â”€ 05_mlflow_tracking.md        # ì‹¤í—˜ ì¶”ì 
â””â”€â”€ 06_common_patterns.md        # ê³µí†µ íŒ¨í„´ & íŒ
```

## ğŸš€ Quick Start

```bash
# uv ì„¤ì¹˜
curl -LsSf https://astral.sh/uv/install.sh | sh

# í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
uv init ml-project
cd ml-project

# ì˜ì¡´ì„± ì¶”ê°€
uv add torch transformers peft bitsandbytes accelerate datasets mlflow

# GPU ì§€ì› PyTorch (CUDA 12.4)
uv add torch --index-url https://download.pytorch.org/whl/cu124
```

## ğŸ¯ Key Principles

1. **í™˜ê²½ ê²©ë¦¬**: uvë¡œ ê°€ìƒí™˜ê²½ ìë™ ê´€ë¦¬
2. **ì¬í˜„ì„±**: uv.lockìœ¼ë¡œ ì •í™•í•œ ë²„ì „ ê³ ì •
3. **ë©”ëª¨ë¦¬ íš¨ìœ¨**: 4-bit/8-bit ì–‘ìí™”ë¡œ VRAM ì ˆì•½
4. **ì‹¤í—˜ ì¶”ì **: MLflowë¡œ ëª¨ë“  ì‹¤í—˜ ê¸°ë¡
5. **ì„±ëŠ¥**: torch.compile()ë¡œ 2-3x ì†ë„ í–¥ìƒ

## ğŸ“Œ Version Compatibility Matrix

```
Python 3.12 â”€â”¬â”€ PyTorch 2.4+ (torch.compile ì§€ì›)
             â”œâ”€ CUDA 12.1+ ê¶Œì¥
             â””â”€ bitsandbytes 0.43+

transformers 4.40+ â”€â”¬â”€ BitsAndBytesConfig ì§€ì›
                    â””â”€ PEFT 0.10+ í˜¸í™˜
```

## âš ï¸ Common Pitfalls

- `pip install` ëŒ€ì‹  `uv add` ì‚¬ìš©
- PyTorch: `device_map="auto"`ëŠ” **ì¶”ë¡  ì „ìš©**
- 4-bit ì–‘ìí™”: `bnb_4bit_compute_dtype=torch.bfloat16` í•„ìˆ˜
- MLflow: `mlflow.pytorch.autolog()`ëŠ” Lightningì—ì„œë§Œ ë™ì‘

## ğŸ”— References

- [PyTorch Performance Tuning Guide](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)
- [HuggingFace Quantization](https://huggingface.co/docs/transformers/quantization/bitsandbytes)
- [MLflow PyTorch Guide](https://mlflow.org/docs/latest/ml/deep-learning/pytorch/)
- [uv Documentation](https://docs.astral.sh/uv/)

# Current Training Session

## Status: âœ… COMPLETED (2026-01-19 22:42)

### Training Details
- **Script**: `ml-service/scripts/train_toxic_classifier.py`
- **Mode**: extended
- **Duration**: ~40 minutes (6 epochs, early stopping)
- **Output**: `ml-service/models/toxic-classifier/`

### Configuration
| Setting | Value |
|---------|-------|
| Model | bert-base-uncased + QLoRA |
| Dataset | Jigsaw Toxic (23K train / 2.5K val) |
| Planned Epochs | 20 |
| Actual Epochs | 6 (early stopping) |
| Batch Size | 4 |
| Grad Accumulation | 8 |
| Effective Batch | 32 |
| LoRA r | 64 |
| LoRA alpha | 16 |

### Final Results ðŸŽ‰
| Metric | Value |
|--------|-------|
| **Train Loss** | 0.1750 |
| **Eval Loss** | 0.1843 |
| **Accuracy** | **92.76%** |
| **F1 Score** | **92.77%** |
| **Precision** | 92.96% |
| **Recall** | 92.76% |

### Timeline
- Started: 2026-01-19 22:03
- Completed: 2026-01-19 22:42
- Duration: ~40 minutes

### Notes
- Early stopping at epoch 6 (loss converged)
- Much faster than expected (8hr estimate â†’ 40min actual)
- Model saved to `models/toxic-classifier/adapter_model.safetensors`

### Post-Training Actions âœ…
1. [x] Check `final_metrics.txt` for results
2. [x] Update graphs with real metrics
3. [x] Update roadmap to 100%
4. [ ] Commit the trained model info

---
*Updated: 2026-01-20*
